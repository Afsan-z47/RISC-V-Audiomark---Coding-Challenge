vlenb = vector register size in bytes

- working with 16 bit values
- may need to widen to 32 bit for accuracy

max LMUL 8 registers

max element amount vlen/2 * 8 = vlen * 4 for 16 bits

max element amount vlen/4 * 8 = vlen * 2 for 32 bits


-- IMPL 1 --

loop count = n / element amount;

 vector load 
 ------------- 
 
 acc = a[i] + alpha * b[i]
 --------------------------
 
 vmadd.vx vd, rs1, vs2, vm    # vd[i] = (x[rs1] * vd[i]) + vs2[i]
 ## or widen it
 vwmacc.vx vd, rs1, vs2, vm    # vd[i] = +(x[rs1] * vs2[i]) + vd[i]
 
 y[i] = sat(acc)
 ----------------


Fix left overs: ? 



-- IMPL 2 --

# Signed multiply, returning low bits of product
vmul.vv vd, vs2, vs1, vm   # Vector-vector
vmul.vx vd, vs2, rs1, vm   # vector-scalar

# Signed multiply, returning high bits of product
vmulh.vv vd, vs2, vs1, vm   # Vector-vector
vmulh.vx vd, vs2, rs1, vm   # vector-scalar


These instructions along with masking may be used to like, 
- Load
- If high bits > 0
	-> Use it as a mask to clip the value to something
  else
	- Mask the other half of the result
	- Done

- Store


--------------------------------------------------------------


void saxpy_rvv(size_t n, const float a, const float *x, float *y) {
for (size_t vl; n > 0; n -= vl, x += vl, y += vl) {
	vl = __riscv_vsetvl_e32m8(n);
// Load x[i..i+vl)
	vfloat32m8_t vx = __riscv_vle32_v_f32m8(x, vl);
// Load y[i..i+vl)
	vfloat32m8_t vy = __riscv_vle32_v_f32m8(y, vl);
// Computes vy[0..vl) + a*vx[0..vl)
// and stores it in y[i..i+vl)
	__riscv_vse32_v_f32m8(y, __riscv_vfmacc_vf_f32m8(vy, a, vx, vl), vl);
}


[Dont do external loops, use vsetvl to do the whole job]

void q15_axpy_rvv(const int16_t *a, const int16_t *b,
                  int16_t *y, int n, int16_t alpha)
{       
    size_t i = 0;
    while(i < n) {
        size_t vl = __riscv_vsetvl_e16m4(n-i);
        
        vint16m4_t va = __riscv_vle16_v_i16m4(&a[i], vl);
        vint16m4_t vb = __riscv_vle16_v_i16m4(&b[i], vl);
        vint32m8_t va_extended = __riscv_vsext_vf2_i32m8(va, vl);
        vint32m8_t vd = __riscv_vwmacc_vx_i32m8(va_extended, alpha, vb, vl);
        vint16m4_t sat_vd = __riscv_vnclip_wx_i16m4(vd, 0, __RISCV_VXRM_RDN, vl);

        // Store - may reduce vl on fault
        __riscv_vse16_v_i16m4(&y[i], sat_vd, vl);
        
        // Check if fault occurred (vl was reduced)
        size_t actual_vl = __riscv_read_vl();
        
        if (actual_vl < vl) {
            // Fault occurred - trap handler may have page-fixed the fault
            // Retry with reduced vl (handler may have unblocked one page)
            __riscv_vsetvl_e16m4(actual_vl);  // Reset vl to what succeeded
            __riscv_vse16_v_i16m4(&y[i + actual_vl], sat_vd, vl - actual_vl);
            
            // Now read final vl
            size_t retry_vl = __riscv_read_vl();
            i += actual_vl + retry_vl;
        } else {
            // No fault - advance normally
            i += vl;
        }
    } 
}
